---
title: "Project_text_draft"
author: "Egor Balalykin"
format: html
---

## Introduction.Topic Description and Relevance

The rapid development of Artificial Intelligence (AI) technologies has sparked significant policy debates about how to regulate and govern AI to ensure it benefits society without compromising core human values. Traditionally, the focus of AI governance has been on aspects such as innovation, security, and competitiveness, but there is an emerging framework called Digital Humanism that challenges these techno-centric approaches.
Digital Humanism advocates for a more human-centered approach to AI governance, where human dignity, rights, and democratic values are prioritized. Rooted in European humanist traditions, this framework emphasizes the ethical design of algorithms, transparency, and accountability in AI systems, as well as the importance of democratic control over AI technologies (Floridi and Cowls, 2019; Vienna Manifesto, 2019). This perspective critiques the dominant techno-solutionism that seeks to solve societal challenges by merely enhancing technological capabilities (Morozov, 2013).
This policy brief explores the European Union's approach to AI governance, particularly whether its policy documents adopt the Digital Humanism framework or whether they primarily emphasize the more common frames of Innovation and Security. This is timely because the EU has been a global leader in pushing for ethical AI through initiatives like the AI Act and calls for trustworthy AI (European Commission, 2020b).
By analyzing the framing of AI governance in key EU policy texts, this study aims to contribute to the ongoing debate about how AI should be governed in ways that preserve democratic values and human rights.

## Research Question and Objections

**RQ**:
How do European Union policy documents frame AI governance: as a matter of innovation, security, or digital humanism?

**Objectives**:
- To examine how the EU frames the issue of AI governance in different policy documents.
- To identify which framing – Innovation, Security, or Digital Humanism – is most prominent in EU policy discourse on AI.
- To analyze the implications of these frames for ethical AI governance and the future regulation of AI technologies within the EU. The focus of the research will be to examine the use of key terms and language patterns in three key EU policy documents related to AI. It will look at how often and in what ways terms linked to human values, such as dignity, rights, and democratic control appear in texts, compared to terms linked to economic growth, competitiveness, and safety.

## Data Collection

This project will analyze the following EU policy documents:
1. Proposal for a Regulation on Artificial Intelligence (AI Act) by the European Commission (2021) (European Commission, 2021);
The document is a regulatory framework to AI in the EU. It classifies different levels of risk associated with AI systems and introduces specific measures to ensure AI is trustworthy and safe.
2. European Parliament Resolution on Artificial Intelligence in a Digital Age (2022) (European Parliament, 2022). This resolution looks at the broader implications of AI in our digital society, with particular attention to its impact on human rights, ethical standards, and economic life.

## Methods and Validation

Analytical Approach:

In order to better understand the content of the selected policy documents, we will use a quantitative text analysis (QTA) method, carried out with the help of the quanteda package in R Studio. We will create three custom dictionaries to identify terms associated with the three main frames:

1. Digital Humanism: ethics, dignity, rights, justice, democracy, transparency
2. Innovation: innovation, competitiveness, entrepreneurship, growth, investment
3. Security: risk, surveillance, protection, liability, danger
Our team intends to use the dfm_lookup() function to identify the frequency of these terms in the texts. In addition to that, we will carry out sentiment analysis using the Lexicoder Sentiment Dictionary (LSD) in order to determine the emotional valence of the language, whether positive, negative, or neutral.

Validation Strategy:
Our team intends to ensure that the results are reliable. Thus, we plan to manually review the matched terms to check their context and avoid misinterpretation. This way we will avoid potential false positives or negatives. Additionally, we consider applying a technique called Latent Dirichlet Allocation (LDA), which will help us to uncover underlying topics in the texts. Comparing these topics with the dictionary-based findings will give us a more well-rounded view.

Limitations:
We consider that there are some potential limitations we should keep in mind. Ambiguity in terms: Some terms may appear in multiple contexts and may require
manual/human interpretation.
Small sample size: The analysis is based on a small number of documents, which may limit the generalizability of the findings. However, we would like to emphasize that we are considering identifying other important EU policy documents and if we consider appropriate in the working process to analyse them as well.
